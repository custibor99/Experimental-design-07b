{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f442cd55-a811-4a69-955e-e47c9c71d11f",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- The original authors build univariate models\n",
    "    - Created one multivariate model per variable in dataset\n",
    "    - Computed mse and mae based on all of their results\n",
    "- Reference articles ceated univariate and multivariate models.\n",
    "    - The univariate models were only build with the OT variable\n",
    "- The splits assume a month is 30 days long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594e9ce2-b455-41e9-b178-05e28d6711d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple, Iterator, List\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e386248-313c-4f3d-be48-93550d59bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, filepath:str):\n",
    "        self.filepath = filepath\n",
    "        self.dataset_name = self.filepath.split(\"/\")[-1].split(\".\")[0]\n",
    "        self.df = self.load_data(self.filepath)\n",
    "        self.columns = self.df.columns\n",
    "    \n",
    "    def load_data(self, filepath:str) -> pd.DataFrame:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df = df.drop(columns=\"date\")\n",
    "        return df\n",
    "\n",
    "    def get_train_test_data(self, df:pd.DataFrame, input_size = 672, padding=True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        n, d = df.shape\n",
    "        breakpoint = int(n*0.8)\n",
    "        train = df.iloc[0:breakpoint]\n",
    "        test = df.iloc[breakpoint-input_size:] if padding else df.iloc[breakpoint:]\n",
    "        return train, test\n",
    "    \n",
    "    def get_lag_response_and_dependent(self, df: pd.DataFrame, input_size: int, horizon_size:int)-> pd.DataFrame:\n",
    "        n, d = df.shape\n",
    "        w = input_size\n",
    "        h = horizon_size\n",
    "        X = np.zeros([n + 1 - w - h, d*w])\n",
    "        y = np.zeros([n + 1 - w - h, d*h])\n",
    "        x_flat = df.values.flatten()\n",
    "        for i in range(0,n + 1 - w - h):\n",
    "            X[i] = x_flat[i*d:d*(i+w)]\n",
    "            y[i] = x_flat[d*(i+w):d*(i+w) + d*h]\n",
    "        return X, y\n",
    "\n",
    "    def build_dataset(self, input_size = 672, horizon_size = 24, cut_off=0.75) -> Iterator[Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]]:\n",
    "        df = self.df.copy()\n",
    "        #Build train and test dataset\n",
    "        train, test = self.get_train_test_data(df, input_size = input_size)\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        cut_off = int(len(train)*cut_off)\n",
    "        self.columns = train.columns\n",
    "        sc.fit(train.iloc[0:cut_off])\n",
    "        train = pd.DataFrame(sc.transform(train))\n",
    "        test = pd.DataFrame(sc.transform(test))\n",
    "        \n",
    "        X_train, y_train = self.get_lag_response_and_dependent(train, input_size, horizon_size)\n",
    "        X_test, y_test = self.get_lag_response_and_dependent(test, input_size, horizon_size)\n",
    "\n",
    "        X_train = pd.DataFrame(X_train)\n",
    "        y_train = pd.DataFrame(y_train)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "        y_test = pd.DataFrame(y_test)\n",
    "\n",
    "        # Create hierarhical columns\n",
    "        X_cols_lvl2 = [ f\"t={i-input_size}\" for i in range(0,input_size) for _ in range(len(self.columns))]\n",
    "        X_cols_lvl1 = [col for _ in range(input_size) for col in self.columns]\n",
    "        X_cols = pd.MultiIndex.from_tuples(zip(X_cols_lvl1, X_cols_lvl2))\n",
    "        y_cols_lvl2 = [ f\"t={i}\" for i in range(0,horizon_size) for _ in range(len(self.columns))]\n",
    "        y_cols_lvl1 = [col for _ in range(horizon_size) for col in self.columns]\n",
    "        y_cols = pd.MultiIndex.from_tuples(zip(y_cols_lvl1, y_cols_lvl2))\n",
    "        X_train.columns = X_cols\n",
    "        y_train.columns = y_cols\n",
    "        X_test.columns = X_cols\n",
    "        y_test.columns = y_cols\n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "class ETTDataLoader(DataLoader):\n",
    "    def __init__(self, filepath:str, months=20, day_length=24):\n",
    "        self.filepath = filepath\n",
    "        self.months = months\n",
    "        self.dataset_name = self.filepath.split(\"/\")[-1].split(\".\")[0]\n",
    "        self.boundries = [0, day_length*16*30, day_length*20*30]\n",
    "        self.df = self.load_data(self.filepath)\n",
    "        self.columns = self.df.columns\n",
    "        \n",
    "    def load_data(self, filepath:str) -> pd.DataFrame:\n",
    "        # Read file\n",
    "        ett = pd.read_csv(filepath)\n",
    "        ett = ett.drop(columns=\"date\")\n",
    "        \n",
    "        #get correct rows\n",
    "        ett = ett.iloc[0:self.boundries[2]]\n",
    "        return ett\n",
    "        \n",
    "    def get_train_test_data(self, df:pd.DataFrame, input_size = 672, padding=True, day_length=20) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        tmp = df.copy()\n",
    "        train = tmp.iloc[0: self.boundries[1]]\n",
    "        test = tmp.iloc[self.boundries[1]:]\n",
    "        if padding:\n",
    "            test = pd.concat([train.iloc[-input_size:], test])\n",
    "        return train, test\n",
    "\n",
    "def run_Experiment(data_loaders, horizons, input_size=672):\n",
    "    res = []\n",
    "    lr = LinearRegression()\n",
    "    dataset_names = []\n",
    "    for j, loader in enumerate(dataLoaders):\n",
    "        mse = np.zeros([1, len(horizons)])\n",
    "        mae = np.zeros([1, len(horizons)])\n",
    "        for i, h in enumerate(horizons):\n",
    "            diffs = []\n",
    "            for col in tqdm(loader.columns):\n",
    "                X_train, y_train, X_test, y_test = loader.build_dataset(horizon_size=h, input_size=input_size)\n",
    "                lr.fit(X_train[col], y_train[col])\n",
    "                y_pred = lr.predict(X_test[col])\n",
    "                diff = y_pred - y_test[col].values\n",
    "                diffs += list(diff)\n",
    "            diffs = np.array(diffs)\n",
    "            mae[0,i] = np.mean(np.abs(diffs))\n",
    "            mse[0,i] = np.mean(diffs**2)\n",
    "        res.append(mae[0])\n",
    "        res.append(mse[0])\n",
    "    \n",
    "    \n",
    "    dataset_names = [l.dataset_name for l in dataLoaders for i in range(2)]\n",
    "    metrics = [metric for metric in (\"mae\", \"mse\") for i in range(len(dataLoaders))]\n",
    "    ml_index = pd.MultiIndex.from_arrays([dataset_names, metrics])\n",
    "    return pd.DataFrame(res, index=ml_index, columns=horizons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7621cf-56f9-49e5-b5d2-75ec9bb73d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Experiment(data_loaders, horizons, input_size=672):\n",
    "    res = []\n",
    "    lr = LinearRegression()\n",
    "    dataset_names = []\n",
    "    for j, loader in enumerate(dataLoaders):\n",
    "        mse = np.zeros([1, len(horizons)])\n",
    "        mae = np.zeros([1, len(horizons)])\n",
    "        for i, h in enumerate(horizons):\n",
    "            diffs = []\n",
    "            for col in tqdm(loader.columns):\n",
    "                X_train, y_train, X_test, y_test = loader.build_dataset(horizon_size=h, input_size=input_size)\n",
    "                lr.fit(X_train[col], y_train[col])\n",
    "                y_pred = lr.predict(X_test[col])\n",
    "                diff = y_pred - y_test[col].values\n",
    "                diffs += list(diff)\n",
    "            diffs = np.array(diffs)\n",
    "            mae[0,i] = np.mean(np.abs(diffs))\n",
    "            mse[0,i] = np.mean(diffs**2)\n",
    "        res.append(mae[0])\n",
    "        res.append(mse[0])\n",
    "    \n",
    "    \n",
    "    dataset_names = [l.dataset_name for l in dataLoaders for i in range(2)]\n",
    "    metrics = [metric for metric in (\"mae\", \"mse\") for i in range(len(dataLoaders))]\n",
    "    ml_index = pd.MultiIndex.from_arrays([dataset_names, metrics])\n",
    "    return pd.DataFrame(res, index=ml_index, columns=horizons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9825d939-5e89-4a03-9d5b-02c4a94084b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:03<00:00,  1.84it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:05<00:00,  1.20it/s]\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:08<00:00,  1.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>48</th>\n",
       "      <th>168</th>\n",
       "      <th>336</th>\n",
       "      <th>720</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ETTh1</th>\n",
       "      <th>mae</th>\n",
       "      <td>0.357471</td>\n",
       "      <td>0.378909</td>\n",
       "      <td>0.421562</td>\n",
       "      <td>0.445320</td>\n",
       "      <td>0.501034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.304926</td>\n",
       "      <td>0.340621</td>\n",
       "      <td>0.404459</td>\n",
       "      <td>0.433502</td>\n",
       "      <td>0.490237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                24        48        168       336       720\n",
       "ETTh1 mae  0.357471  0.378909  0.421562  0.445320  0.501034\n",
       "      mse  0.304926  0.340621  0.404459  0.433502  0.490237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ETTH\n",
    "etth1DataLoader = ETTDataLoader(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTh1.csv\")\n",
    "etth2DataLoader = ETTDataLoader(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTh2.csv\")\n",
    "\n",
    "dataLoaders = [etth1DataLoader, etth2DataLoader]\n",
    "horizons = [24, 48, 168, 336, 720]\n",
    "etth_res = run_Experiment(dataLoaders, horizons)\n",
    "etth_res.to_csv(\"data/reproduced_results/etth.csv\")\n",
    "\n",
    "## ETTM\n",
    "\n",
    "ettm1DataLoader = ETTDataLoader(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTm1.csv\")\n",
    "dataLoaders = [ettm1DataLoader]\n",
    "horizons = [24, 48, 96, 228, 672]\n",
    "ettm_res = run_Experiment(dataLoaders, horizons)\n",
    "ettm_res.ro_csv(\"data/reproduced_results/ettm.csv\")\n",
    "\n",
    "## ILI\n",
    "iliLoader = DataLoader(\"../exercise2/data/illness-20231205T092100Z-001/illness/national_illness.csv\")\n",
    "dataLoaders = [iliLoader]\n",
    "horizons = [24, 36, 48, 60]\n",
    "ili_res = run_Experiment(dataLoaders, horizons, input_size=96)\n",
    "ili_res.to_csv(\"data/reproduced_results/ili.csv\")\n",
    "\n",
    "##WTH\n",
    "wthLoader = DataLoader(\"../exercise2/data/WTH.csv-20231205T092445Z-001/WTH.csv\")\n",
    "dataLoaders = [wthLoader]\n",
    "horizons = [24, 48, 168, 338, 720]\n",
    "wth_res = run_Experiment(dataLoaders, horizons)\n",
    "wth_res.to_csv(\"data/reproduced_results/wth.csv\")\n",
    "\n",
    "## WEATHER\n",
    "weatherLoader = DataLoader(\"../exercise2/data/weather-20231205T093714Z-001/weather/weather.csv\")\n",
    "dataLoaders = [weatherLoader]\n",
    "horizons = [96, 192, 336, 720]\n",
    "weather_res = run_Experiment(dataLoaders, horizons)\n",
    "weather_res.to_csv(\"data/reproduced_results/weather.csv\")\n",
    "\n",
    "#exchange\n",
    "exchange_rate = DataLoader(\"../exercise2/data/exchange_rate-20231205T092055Z-001/exchange_rate/exchange_rate.csv\")\n",
    "dataLoaders = [exchange_rate]\n",
    "horizons = [24, 36, 48, 60]\n",
    "exchange_res = run_Experiment(dataLoaders, horizons, input_size=31)\n",
    "exchange_res.to_csv(\"data/reproduced_results/exchange.csv\")\n",
    "\n",
    "#ECL\n",
    "ECL = DataLoader(\"../exercise2/data/ECL.csv-20231205T092501Z-001/ECL.csv\")\n",
    "dataLoaders = [ECL]\n",
    "horizons = [48, 168, 336, 720, 960]\n",
    "ecl_res = run_Experiment(dataLoaders, horizons)\n",
    "ecl_res.to_csv(\"data/reproduced_results/ecl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a13d1b-620d-4cb1-9a92-b5b9192e516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rate = DataLoader(\"../exercise2/data/exchange_rate-20231205T092055Z-001/exchange_rate/exchange_rate.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
