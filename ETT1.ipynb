{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594e9ce2-b455-41e9-b178-05e28d6711d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple, Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e386248-313c-4f3d-be48-93550d59bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, filepath:str):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_train_test_data(self, horizn_size: int, input_size: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_lag_response_and_dependent(self, df: pd.DataFrame, input_size: int, horizon_size:int )-> pd.DataFrame:\n",
    "        n, d = df.shape\n",
    "        w = input_size\n",
    "        h = horizon_size\n",
    "        res_df = np.zeros([n + 1 - w - h,d * w + d * h])\n",
    "        flat = df.values.flatten()\n",
    "        for i in range(0, res_df.shape[0]):\n",
    "            tmp = flat[i*d:i*d + d*(w+h)]\n",
    "            res_df[i,:] = tmp\n",
    "        X = res_df[:, 0:w*d]\n",
    "        y = res_df[:, w*d:]\n",
    "        return X, y\n",
    "    \n",
    "    def get_datasets(self, train_size_months = 16, input_size = 672, horizon_size = 24, cut_off=0.75) -> Iterator[Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]]:\n",
    "        df = self.df.copy()\n",
    "        #Build train and test dataset\n",
    "        train, test = self.get_train_test_data(df, input_size = input_size, train_size_months = train_size_months)\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        cut_off = int(len(train)*cut_off)\n",
    "        sc.fit(train.iloc[0:cut_off])\n",
    "        train = pd.DataFrame(sc.transform(train))\n",
    "        test = pd.DataFrame(sc.transform(test))\n",
    "        \n",
    "        X_train, y_train = self.get_lag_response_and_dependent(train, input_size, horizon_size)\n",
    "        X_test, y_test = self.get_lag_response_and_dependent(test, input_size, horizon_size)\n",
    "        d = train.shape[1]\n",
    "        for p in range(0, train.shape[1]):\n",
    "            x_cols = [i*d + p for i in range(0,input_size)]\n",
    "            y_cols = [i*d + p for i in range(0, horizon_size)]\n",
    "            yield X_train[:, x_cols], y_train[:, y_cols], X_test[:, x_cols], y_test[:, y_cols]\n",
    "    \n",
    "\n",
    "class ETTDataLoader(DataLoader):\n",
    "    def __init__(self, filepath:str, months=20):\n",
    "        self.filepath = filepath\n",
    "        self.months = months\n",
    "        self.dataset_name = self.filepath.split(\"/\")[-1].split(\".\")[0]\n",
    "        self.df = self.load_data()\n",
    "        self.vars = [\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
    "        \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        # Read file\n",
    "        ett = pd.read_csv(self.filepath)\n",
    "\n",
    "        #Check if it contains all columns\n",
    "        expected_columns = [\"date\", \"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
    "        for expected in expected_columns:\n",
    "            assert expected in ett.columns, f\"Column: {expected} not in dataframe.\"\n",
    "\n",
    "        #Convert data types\n",
    "        ett[\"date\"] = pd.to_datetime(ett[\"date\"])\n",
    "\n",
    "        #get correct rows\n",
    "        start_date = ett[\"date\"].min()\n",
    "        ett = ett.loc[ett[\"date\"] < (start_date + pd.DateOffset(months=self.months))]\n",
    "        return ett\n",
    "        \n",
    "    def get_train_test_data(self, df:pd.DataFrame, input_size = 672, train_size_months = 16, padding=True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        tmp = df.copy()\n",
    "        start_date = tmp[\"date\"].min()\n",
    "        mask = tmp[\"date\"] < (start_date + pd.DateOffset(months=train_size_months))\n",
    "        train = tmp.loc[mask].drop(columns = \"date\")\n",
    "        test = tmp.loc[~mask].drop(columns = \"date\")\n",
    "        if padding:\n",
    "            test = pd.concat([train.iloc[-input_size:], test])\n",
    "        return train, test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea7a000-6a36-44b2-af5e-e8753cb4fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataLoader: DataLoader, horizons, input_sizes):\n",
    "    lr = LinearRegression(fit_intercept = False)\n",
    "    for i, h in enumerate(horizons):\n",
    "        mse = mae = div = 0\n",
    "        Datasets = dataLoader.get_datasets(horizon_size=horizons[i], input_size=input_sizes[i])\n",
    "        for X_train, y_train, X_test, y_test in Datasets:\n",
    "            lr = lr.fit(X_train, y_train)\n",
    "            predict = lr.predict(X_test)\n",
    "            div += predict.shape[0] * predict.shape[1]\n",
    "            mae += np.sum(np.abs(predict - y_test))\n",
    "            mse += np.sum((predict-y_test)**2)\n",
    "        print(f\"mse: {np.mean(mse/div)}, mae: {np.mean(mae/div)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61061edb-99e3-4844-996c-cdda3c6003c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.3041115416681451, mae: 0.35498849323911175\n",
      "mse: 0.3420245243955977, mae: 0.37838870757472953\n",
      "mse: 0.4087140800542539, mae: 0.42405140637412\n",
      "mse: 0.4445914994704474, mae: 0.4510744424444385\n",
      "mse: 0.5020965155296265, mae: 0.5028583444464008\n",
      "CPU times: user 1min 19s, sys: 42 s, total: 2min 1s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dl = ETTDataLoader(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTh1.csv\")\n",
    "run_experiment(dl, horizons = [24, 48, 168, 336, 720], input_sizes = [672, 672, 672, 672, 672])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96f2ce-095a-478c-a861-6a91ca9b1606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.17109527657886725, mae: 0.26583507708955284\n",
      "mse: 0.22350248970878317, mae: 0.30426933417387936\n",
      "mse: 0.33732819848543993, mae: 0.3857293397885034\n",
      "mse: 0.42400305895576784, mae: 0.44269177032103946\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dl = ETTDataLoader(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTh2.csv\")\n",
    "run_experiment(dl, horizons = [24, 48, 168, 336, 720], input_sizes = [672, 672, 672, 672, 672])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cd66a-dfd1-4d90-96d7-c622a40508d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dl = ETTDataLoader(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTm1.csv\")\n",
    "run_experiment(dl, horizons = [24, 48, 168, 336, 720], input_sizes = [672, 672, 672, 672, 672])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66085b-a461-4b7f-b9f2-1c14b8b98f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../exercise2/data/ETT-small-20231205T092053Z-001/ETT-small/ETTm1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
